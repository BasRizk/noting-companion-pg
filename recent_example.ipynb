{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules before executing a script\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from typing import List\n",
    "from parsers.nb_parser import NotebookParser\n",
    "from analyze_nb_logs import load_object, get_all_file_with_extension_in_dir_recursively, logger, LogParser\n",
    "\n",
    "\n",
    "notebooks_dir = 'data/tac_notebooks'\n",
    "logs_dir = 'data/tac_raw_logs'\n",
    "all_log_filepathes = get_all_file_with_extension_in_dir_recursively(logs_dir, \".log\")\n",
    "all_log_filepathes.sort()\n",
    "# skip files containing baseline\n",
    "all_log_filepathes = [log_filepath for log_filepath in all_log_filepathes if \"baseline\" not in log_filepath]\n",
    "logger.success(f'There are {len(all_log_filepathes)} log files in {logs_dir} directory')\n",
    "\n",
    "halt = False\n",
    "for selected_log_filepath in all_log_filepathes:\n",
    "    log_parser = LogParser(selected_log_filepath).parse()\n",
    "    nb_sublog_dict = log_parser.attach_notebooks(notebooks_dir, verbose=False)\n",
    "    # logger.debug(\n",
    "    #     'Sample:' +\\\n",
    "    #     f'\\nSelected log file: {selected_log_filepath}' +\\\n",
    "    #     f'\\nfetching notebooks from log file: {notebooks_dir}' +\\\n",
    "    #     f'\\nLog parser per these notebooks:\\n{nb_sublog_dict.keys()}'\n",
    "    # )\n",
    "\n",
    "    from nb_progress import get_notebook_progress_using_log, InvalidLogError, NotebookStateLogMismatchError\n",
    "\n",
    "\n",
    "    for i, (nb_filepath, (nb_log_parser, nb_parser)) in enumerate(nb_sublog_dict.items()):\n",
    "        try:\n",
    "            nb_progress = get_notebook_progress_using_log(nb_parser, nb_log_parser)\n",
    "        except InvalidLogError as e:\n",
    "            # logger.error(f'@ {i} Exception: {e} with nb_filepath({nb_parser.filepath}) and nb_log_parser({nb_log_parser.filepath})')\n",
    "            continue\n",
    "        except NotebookStateLogMismatchError as e:\n",
    "            # logger.error(f'@ {i} Exception: {e} with nb_filepath({nb_parser.filepath}) and nb_log_parser({nb_log_parser.filepath})')\n",
    "            continue\n",
    "\n",
    "\n",
    "        nb_states: List[NotebookParser] = []\n",
    "        for step_i, step in enumerate(nb_progress):\n",
    "            step.reset()\n",
    "            if len(step) == 0:\n",
    "                nb_states.append(step.nb_parser_state)\n",
    "            else:\n",
    "                # prev_msgs = [] # TODO should I reset prev_msgs upon each completed step?\n",
    "                for change_i, nb_parser_with_change_applied in enumerate(step):\n",
    "                    nb_states.append(\n",
    "                        nb_parser_with_change_applied\n",
    "                    )\n",
    "\n",
    "        num_progress_steps = len(nb_progress)\n",
    "\n",
    "\n",
    "        # TODO DEBUGGING HERE\n",
    "        if num_progress_steps >= 4:\n",
    "            logger.info(f'Notebook: {nb_parser.filepath}')\n",
    "            logger.info(f'Log: {nb_log_parser.filepath}')\n",
    "            logger.info(f'Number of progress steps: {num_progress_steps}')\n",
    "            halt = True\n",
    "            break\n",
    "\n",
    "    if halt:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nb_state in enumerate(nb_states):\n",
    "    path = nb_state.to_notebook(directory='__nb_states', filepath_postfix=f'_{i}')\n",
    "    logger.info(f'Notebook state saved to: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_parser.filepath, nb_log_parser.filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prompts.generate_questions_per_changes import _get_nb_states_updates\n",
    "# _get_nb_states_updates(nb_states[0], nb_states[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.code_explain_change import (\n",
    "    get_diff_nb_states,\n",
    ")\n",
    "diffs = []\n",
    "for i in range(len(nb_states)):\n",
    "    for j in range(i+1, len(nb_states)):\n",
    "        print(f\"Comparing {i} and {j}\")\n",
    "        print('='*80)\n",
    "        diffs.append(get_diff_nb_states(nb_states[i], nb_states[j]))\n",
    "        print(diffs[-1])\n",
    "        print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from tqdm import tqdm\n",
    "# from prompts.code_explain_change import (\n",
    "#     get_diff_nb_states,\n",
    "#     code_explain_change\n",
    "# )\n",
    "\n",
    "# changes_exps_dict = {}\n",
    "# for i in range(len(nb_states)):\n",
    "#     for j in range(i+1, len(nb_states)):\n",
    "#         changes_exps_dict[(i, j)] = None\n",
    "\n",
    "# with tqdm(total=len(changes_exps_dict), desc='Computing changes between states') as pbar:\n",
    "#     for t1, t2 in list(changes_exps_dict.keys()):\n",
    "#         pbar.set_postfix_str(f'{t1} -> {t2}')\n",
    "\n",
    "#         changes_exps_dict[(t1, t2)] = code_explain_change(\n",
    "#             nb_states[t1],\n",
    "#             nb_states[t2]\n",
    "#         )\n",
    "#         print('='*100)\n",
    "#         print(f'Changes between states {t1} and {t2}')\n",
    "#         print(json.dumps(changes_exps_dict[(t1, t2)], indent=4))\n",
    "#         print('='*100)\n",
    "\n",
    "#         pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (t1, t2), changes_exp in changes_exps_dict.items():\n",
    "#     print('='*100)\n",
    "#     print(f'Changes between {t1} and {t2}')\n",
    "#     print(json.dumps(changes_exp, indent=4))\n",
    "#     print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.generate_questions_per_changes import make_questions_prompt\n",
    "\n",
    "questions_dict = {}\n",
    "for i in range(len(nb_states)):\n",
    "    for j in range(i+1, len(nb_states)):\n",
    "        questions_dict[(i, j)] = None\n",
    "\n",
    "\n",
    "for (t1, t2) in questions_dict.keys():\n",
    "    print('='*100)\n",
    "    print(f'Question on changes between {t1} and {t2}')\n",
    "    # print(json.dumps(changes_exp, indent=4))\n",
    "    print('-'*100)\n",
    "    questions_dict[(t1, t2)] = make_questions_prompt(\n",
    "        nb_states[t1],\n",
    "        nb_states[t2],\n",
    "        # changes_exps_dict[(t1, t2)] # TODO try to use this as hints\n",
    "    )\n",
    "    for i, question in enumerate(questions_dict[(t1, t2)]):\n",
    "        print(f'Q{i+1}: {question}')\n",
    "    print('='*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from prompts.answer_questions_per_change import answer_questions\n",
    "\n",
    "rets_dict = {}\n",
    "answers_dict = {}\n",
    "for (t1, t2), questions in questions_dict.items():\n",
    "    print('='*100)\n",
    "    print(f'Answers between {t1} and {t2}')\n",
    "\n",
    "    answers_dict[(t1, t2)], ret1, ret2 = answer_questions(\n",
    "        nb_states[t1],\n",
    "        nb_states[t2],\n",
    "        questions,\n",
    "        # changes_exps_dict[(t1, t2)], # TODO it is not used yet\n",
    "    )\n",
    "    rets_dict[(t1, t2)] = (ret1, ret2)\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers_dict[(t1, t2)])):\n",
    "        print('-'*100)\n",
    "        print(f'Q{i+1}:', question)\n",
    "        print(f'A{i+1}:', answer)\n",
    "\n",
    "    print('='*100)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from prompts.generate_questions_per_changes import _get_nb_states_updates\n",
    "\n",
    "for t1, t2 in rets_dict.keys():\n",
    "    questions = questions_dict[(t1, t2)]\n",
    "    answers = answers_dict[(t1, t2)]\n",
    "    ret1, ret2 = rets_dict[(t1, t2)]\n",
    "    print('='*100)\n",
    "    print(f'Between {t1} and {t2}')\n",
    "    # print('Notebook 1:')\n",
    "    # print(nb_states[t1])\n",
    "    print('Update:')\n",
    "    print(json.dumps(_get_nb_states_updates(nb_states[t1], nb_states[t2]), indent=4))\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers)):\n",
    "        print('>'*100)\n",
    "        print(f'Q{i+1}:', question)\n",
    "        print(f'A{i+1}:', answer)\n",
    "        print('-'*100)\n",
    "        print('>> context_t1')\n",
    "        for doc_loader in ret1.invoke(question):\n",
    "            code_snippet = eval(doc_loader.page_content)\n",
    "            print('cell_type', code_snippet['cell_type'])\n",
    "            print('id', code_snippet['id'])\n",
    "            print('source:')\n",
    "            print('\\n'.join(code_snippet['source']))\n",
    "            print('-'*100)\n",
    "\n",
    "        print('-'*100)\n",
    "        print('>> context_t2')\n",
    "        for doc_loader in ret2.invoke(question):\n",
    "            code_snippet = eval(doc_loader.page_content)\n",
    "            print('cell_type', code_snippet['cell_type'])\n",
    "            print('id', code_snippet['id'])\n",
    "            print('source:')\n",
    "            print('\\n'.join(code_snippet['source']))\n",
    "            print('-'*100)\n",
    "\n",
    "        print('<'*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_qa_table_to_file(questions_dict, answers_dict, nb_states):\n",
    "#     from typing import List, Tuple\n",
    "#     from parsers.nb_parser import CellEntry\n",
    "\n",
    "#     from tabulate import tabulate\n",
    "#     from utils import prettify_str\n",
    "#     TEXT_WIDTH = 30\n",
    "\n",
    "\n",
    "#     content_table = [\n",
    "#         ['t1', 't2', 'q_a_table', 'diffs']\n",
    "#     ]\n",
    "#     for (t1, t2), questions in questions_dict.items():\n",
    "#         # print('='*100)\n",
    "#         # print(f'Questions and Answers between {t1} and {t2}')\n",
    "#         diffs: List[Tuple[CellEntry]] = get_diff_nb_states(nb_states[t1], nb_states[t2])\n",
    "#         diffs = [\n",
    "#             [cell_t1.tabulate(text_width=TEXT_WIDTH), cell_t2.tabulate(text_width=TEXT_WIDTH)]\n",
    "#             for cell_t1, cell_t2 in diffs\n",
    "#         ]\n",
    "#         diffs = tabulate([[table] for table in [\n",
    "#             tabulate([diff], tablefmt='fancy_grid', headers=['t1', 't2'])\n",
    "#             for diff in diffs\n",
    "#         ]], tablefmt='fancy_grid')\n",
    "#         # print(diffs)\n",
    "#         questions = [\n",
    "#             question[2:].strip()\n",
    "#             for question in questions.split('\\n')\n",
    "#         ]\n",
    "#         tabulated_question_answer = []\n",
    "#         for i, (question, answer) in enumerate(zip(questions, answers_dict[(t1, t2)])):\n",
    "#             # print('-'*100)\n",
    "#             # print(f'Q{i}:')\n",
    "#             question = prettify_str(question, TEXT_WIDTH)\n",
    "#             # print(question)\n",
    "#             # print(f'A{i}:')\n",
    "#             answer = prettify_str(answer, TEXT_WIDTH)\n",
    "#             # print(answer)\n",
    "\n",
    "#             tabulated_question_answer.append([f'Q{i}', question, f'A{i}', answer])\n",
    "\n",
    "#         q_a_table = tabulate(tabulated_question_answer, tablefmt='fancy_grid', headers=['Q', 'Question', 'A', 'Answer'])\n",
    "\n",
    "#         content_table.append([t1, t2, q_a_table, diffs])\n",
    "\n",
    "#         # print('='*100)\n",
    "\n",
    "#     content_tabulated = tabulate(content_table, tablefmt='fancy_grid', headers='firstrow')\n",
    "#     # print(content_tabulated)\n",
    "#     # write to file\n",
    "\n",
    "#     nb_parser_name = nb_parser.filepath.split('/')[-1]\n",
    "#     nb_log_parser_name = nb_log_parser.filepath.split('/')[-1]\n",
    "#     filepath_out = f'{nb_parser_name}_{nb_log_parser_name}_questions_answers.table'\n",
    "#     with open(filepath_out, 'w') as f:\n",
    "#         f.write(content_tabulated)\n",
    "\n",
    "# write_qa_table_to_file(questions_dict, answers_dict, nb_states)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knic-pg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
